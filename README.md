# ğŸ“ Student Performance Predictor â€“ Streamlit Deployment

A supervised machine learning web application built using **Streamlit** to predict the **final grade of students** based on study habits, attendance, motivation, learning style, and other educational features.

---

## ğŸ“˜ Project Overview

- This project builds and deploys a **Random Forest Classifier** to predict studentsâ€™ final grades.  
- The dataset contains student-related numerical and categorical features.  
- The best-performing trained model is deployed as a **Streamlit web app**.  
- Users can input student data to get real-time predictions of final grades.

---

## ğŸ¯ Objective

The project includes:

ğŸ”¹ Data Cleaning  
ğŸ”¹ Exploratory Data Analysis (EDA)  
ğŸ”¹ Feature Engineering  
ğŸ”¹ Feature Scaling  
ğŸ”¹ Feature Selection  
ğŸ”¹ Model Building (Random Forest)  
ğŸ”¹ Hyperparameter Tuning  
ğŸ”¹ Model Evaluation  
ğŸ”¹ Model Saving using Pickle  
ğŸ”¹ Streamlit Web App Deployment  

---

## ğŸ“‚ Dataset Description

| Component | Description |
|------------|-------------|
| Target Variable | FinalGrade |
| Classes | e.g., A, B, C, D, F (or numeric scale if applicable) |
| Problem Type | Multi-class Classification |
| Features | StudyHours, Attendance, Motivation, LearningStyle, Extracurricular, Resources, OnlineCourses, etc. |

---

## ğŸ§¹ Data Preprocessing Steps

âœ” Dataset loaded using Pandas  
âœ” Checked and handled missing values  
âœ” Removed duplicates  
âœ” Checked and removed Outliers.  
âœ” Scaled numerical features using **StandardScaler**  
âœ” Split dataset into Training and Testing sets (80:20)  

---

## ğŸ“Š Exploratory Data Analysis (EDA)

Visualizations used:

- Histogram  
- Box Plot  
- Count Plot  
- Heatmap Correlation  
- Bar Plot  
- KDE Plot  

EDA helped in:

- Understanding feature distribution  
- Identifying outliers  
- Detecting correlations  
- Checking class balance  

---

## ğŸ¤– Machine Learning Model Implemented

- **Random Forest Classifier** (best-performing model)  

Other models may have been explored (SVM, Logistic Regression, Decision Tree) during experiments in **Colab notebook**.

---

## âš™ï¸ Hyperparameter Tuning

- GridSearchCV applied for optimal parameters  
- Pipeline used to avoid data leakage  

---

## ğŸ“Š Model Evaluation Metrics

Evaluation included:

- Accuracy Score  
- Confusion Matrix  
- Precision, Recall, F1-Score  
- Feature Importance  

---

## ğŸ† Best Performing Model

âœ” Random Forest Classifier selected as the best model  
âœ” Saved using Pickle for deployment  

```python
import pickle

pickle.dump(best_rf_model, open("Models/best_rf_model.pkl", "wb"))
